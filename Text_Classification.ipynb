{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrinathMLOps/MLPractise/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "mfrDjJgg6hap"
      },
      "source": [
        "# üöÄ Text Classification\n",
        "\n",
        "This is a simplified, working version that handles all compatibility issues and creates a complete text classification pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OSURtWh6har"
      },
      "outputs": [],
      "source": [
        "# Install and import everything we need\n",
        "%pip install transformers datasets scikit-learn torch gradio\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3kBCL5G6has"
      },
      "outputs": [],
      "source": [
        "# Create a simple dataset for training\n",
        "print(\"üìä Creating sample dataset...\")\n",
        "\n",
        "# Sample movie reviews with sentiment labels\n",
        "texts = [\n",
        "    \"This movie is absolutely fantastic! I loved every minute of it.\",\n",
        "    \"Terrible film, waste of time and money.\",\n",
        "    \"Amazing cinematography and brilliant acting throughout.\",\n",
        "    \"Boring and predictable storyline, very disappointing.\",\n",
        "    \"One of the best movies I've ever seen, highly recommended!\",\n",
        "    \"Poor script and bad direction, couldn't wait for it to end.\",\n",
        "    \"Great entertainment value, fun for the whole family.\",\n",
        "    \"Awful movie, terrible acting and confusing plot.\",\n",
        "    \"Beautifully crafted story with excellent character development.\",\n",
        "    \"Complete disaster, worst movie of the year.\",\n",
        "    \"Exceptional film with outstanding performances.\",\n",
        "    \"Dull and uninteresting, fell asleep halfway through.\",\n",
        "    \"Masterpiece of cinema, truly inspiring and moving.\",\n",
        "    \"Horrible experience, regret watching this garbage.\",\n",
        "    \"Wonderful storytelling and beautiful visuals.\",\n",
        "    \"Pathetic attempt at filmmaking, completely unwatchable.\",\n",
        "    \"Incredible movie that touched my heart deeply.\",\n",
        "    \"Stupid plot with terrible special effects.\",\n",
        "    \"Brilliant direction and superb soundtrack.\",\n",
        "    \"Waste of talent, poor execution throughout.\"\n",
        "] * 5  # Repeat to have more samples\n",
        "\n",
        "# Labels: 1 = Positive, 0 = Negative\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 5\n",
        "\n",
        "# Split into train and test\n",
        "train_size = int(0.8 * len(texts))\n",
        "train_texts = texts[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "test_texts = texts[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "print(f\"‚úÖ Dataset created!\")\n",
        "print(f\"   Train samples: {len(train_texts)}\")\n",
        "print(f\"   Test samples: {len(test_texts)}\")\n",
        "print(f\"   Positive samples: {sum(train_labels + test_labels)}\")\n",
        "print(f\"   Negative samples: {len(labels) - sum(train_labels + test_labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXNclwZF6hat"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer and model\n",
        "print(\"ü§ñ Loading model and tokenizer...\")\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "print(\"‚úÖ Model and tokenizer loaded!\")\n",
        "\n",
        "# Tokenize datasets\n",
        "print(\"üî§ Tokenizing datasets...\")\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Create datasets\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Convert to Dataset objects\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask'],\n",
        "    'labels': train_labels\n",
        "})\n",
        "\n",
        "test_dataset = Dataset.from_dict({\n",
        "    'input_ids': test_encodings['input_ids'],\n",
        "    'attention_mask': test_encodings['attention_mask'],\n",
        "    'labels': test_labels\n",
        "})\n",
        "\n",
        "print(\"‚úÖ Tokenization completed!\")\n",
        "print(f\"   Train dataset: {train_dataset}\")\n",
        "print(f\"   Test dataset: {test_dataset}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HxD_-f6hat"
      },
      "outputs": [],
      "source": [
        "# Universal training function that works with any transformers version\n",
        "print(\"üöÄ Starting training...\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "# Try different training argument configurations\n",
        "training_success = False\n",
        "\n",
        "# Method 1: Try with eval_strategy (newer versions)\n",
        "if not training_success:\n",
        "    try:\n",
        "        print(\"Trying Method 1: eval_strategy parameter...\")\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            eval_strategy='epoch',\n",
        "            save_strategy='epoch',\n",
        "            learning_rate=2e-5,\n",
        "            per_device_train_batch_size=4,\n",
        "            per_device_eval_batch_size=4,\n",
        "            num_train_epochs=2,\n",
        "            weight_decay=0.01,\n",
        "            logging_steps=10,\n",
        "            save_total_limit=2,\n",
        "            report_to=None,\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=test_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        training_success = True\n",
        "        print(\"‚úÖ Training completed with eval_strategy!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Method 1 failed: {e}\")\n",
        "\n",
        "# Method 2: Try with evaluation_strategy (older versions)\n",
        "if not training_success:\n",
        "    try:\n",
        "        print(\"Trying Method 2: evaluation_strategy parameter...\")\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            evaluation_strategy='epoch',\n",
        "            save_strategy='epoch',\n",
        "            learning_rate=2e-5,\n",
        "            per_device_train_batch_size=4,\n",
        "            per_device_eval_batch_size=4,\n",
        "            num_train_epochs=2,\n",
        "            weight_decay=0.01,\n",
        "            logging_steps=10,\n",
        "            save_total_limit=2,\n",
        "            report_to=None,\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=test_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        training_success = True\n",
        "        print(\"‚úÖ Training completed with evaluation_strategy!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Method 2 failed: {e}\")\n",
        "\n",
        "# Method 3: Minimal training (fallback)\n",
        "if not training_success:\n",
        "    try:\n",
        "        print(\"Trying Method 3: minimal training arguments...\")\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            learning_rate=2e-5,\n",
        "            per_device_train_batch_size=4,\n",
        "            num_train_epochs=2,\n",
        "            report_to=None,\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "        training_success = True\n",
        "        print(\"‚úÖ Training completed with minimal arguments!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Method 3 failed: {e}\")\n",
        "\n",
        "if training_success:\n",
        "    print(\"üéâ Training completed successfully!\")\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained('./trained_model')\n",
        "    tokenizer.save_pretrained('./trained_model')\n",
        "    print(\"‚úÖ Model saved to './trained_model'\")\n",
        "\n",
        "    # Evaluate\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"üìä Evaluation results: {eval_results}\")\n",
        "else:\n",
        "    print(\"‚ùå All training methods failed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wmxJgbQ6hau"
      },
      "outputs": [],
      "source": [
        "# Load the trained model for inference\n",
        "print(\"üì• Loading trained model for inference...\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained('./trained_model')\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained('./trained_model')\n",
        "\n",
        "inference_model.eval()\n",
        "print(\"‚úÖ Model loaded for inference!\")\n",
        "\n",
        "# Define prediction function\n",
        "def predict_sentiment(text):\n",
        "    \"\"\"Predict sentiment of input text.\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text\", 0.0\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = inference_tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = inference_model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        confidence, predicted_class = torch.max(predictions, dim=-1)\n",
        "\n",
        "    sentiment = \"Positive üòä\" if predicted_class.item() == 1 else \"Negative üòû\"\n",
        "    confidence_score = confidence.item()\n",
        "\n",
        "    return sentiment, confidence_score\n",
        "\n",
        "# Test the model\n",
        "test_texts = [\n",
        "    \"This movie is absolutely fantastic!\",\n",
        "    \"I hated every moment of this film.\",\n",
        "    \"It was okay, nothing special.\",\n",
        "    \"Amazing story with great acting!\",\n",
        "    \"Boring and predictable plot.\"\n",
        "]\n",
        "\n",
        "print(\"\\nüß™ Testing the model:\")\n",
        "print(\"=\" * 50)\n",
        "for text in test_texts:\n",
        "    sentiment, confidence = predict_sentiment(text)\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Prediction: {sentiment} (Confidence: {confidence:.3f})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"‚úÖ Inference testing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7NZuwez6hav"
      },
      "outputs": [],
      "source": [
        "# Create Gradio interface\n",
        "print(\"üé≠ Creating Gradio interface...\")\n",
        "\n",
        "def gradio_predict(text):\n",
        "    \"\"\"Gradio prediction function.\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text to analyze.\", 0.0\n",
        "\n",
        "    try:\n",
        "        sentiment, confidence = predict_sentiment(text)\n",
        "\n",
        "        # Format result\n",
        "        result = f\"\"\"\n",
        "### üé≠ Sentiment Analysis Result\n",
        "\n",
        "**Text:** \"{text}\"\n",
        "\n",
        "**Prediction:** {sentiment}\n",
        "\n",
        "**Confidence:** {confidence:.1%}\n",
        "        \"\"\"\n",
        "\n",
        "        return result, confidence\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", 0.0\n",
        "\n",
        "# Create the interface\n",
        "with gr.Blocks(title=\"Sentiment Analysis\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 20px;\">\n",
        "        <h1>üé≠ Movie Review Sentiment Analysis</h1>\n",
        "        <p>Enter any text to analyze its sentiment (Positive or Negative)</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"Enter text to analyze\",\n",
        "                placeholder=\"Type your movie review or any text here...\",\n",
        "                lines=3\n",
        "            )\n",
        "            predict_btn = gr.Button(\"Analyze Sentiment\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            confidence_output = gr.Number(\n",
        "                label=\"Confidence Score\",\n",
        "                precision=3\n",
        "            )\n",
        "\n",
        "    result_output = gr.Markdown(\n",
        "        label=\"Analysis Result\",\n",
        "        value=\"Enter text above and click 'Analyze Sentiment' to see results.\"\n",
        "    )\n",
        "\n",
        "    # Examples\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"This movie is absolutely amazing! Best film I've ever seen.\"],\n",
        "            [\"Terrible movie, complete waste of time and money.\"],\n",
        "            [\"It was okay, nothing too special but not bad either.\"],\n",
        "            [\"Brilliant acting and fantastic storyline throughout.\"],\n",
        "            [\"Boring plot with poor character development.\"]\n",
        "        ],\n",
        "        inputs=text_input\n",
        "    )\n",
        "\n",
        "    # Event handlers\n",
        "    predict_btn.click(\n",
        "        fn=gradio_predict,\n",
        "        inputs=text_input,\n",
        "        outputs=[result_output, confidence_output]\n",
        "    )\n",
        "\n",
        "    text_input.submit(\n",
        "        fn=gradio_predict,\n",
        "        inputs=text_input,\n",
        "        outputs=[result_output, confidence_output]\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Gradio interface created!\")\n",
        "print(\"üöÄ Launching interface...\")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(\n",
        "    share=True,  # Creates a public URL\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}